hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)
hold
hold<-data.frame(hold);names(hold)<-c("NOM","POM")
apply(hold, 2, mean)
min(hold)
x<-hold[1,]
min(x)
x
min(x)
x[min(x)]
x==min(x)
apply(hold, 1, function (x) {x==min(x)})
apply(hold, 2, function (x) {x==min(x)})
apply(hold, 1, function (x) {x==min(x)})
t(apply(hold, 1, function (x) {x==min(x)}))
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
out.hold<-lapply(nsp16_lambda1_lambdatrait_0, extract.summary)
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
x<-hold[1,]#
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
out.hold<-lapply(nsp16_lambda1_lambdatrait_1, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
### Which model is better#
x<-hold[1,]#
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/traits/nsp32-1-0.rdata', verbose=T)
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
out.hold<-load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/traits/nsp32-1-0.rdata', verbose=T)
out.hold
out.hold(lapply(nsp32_lambda1_lambdatrait_0, extract.summary))
out.hold<-lapply(nsp32_lambda1_lambdatrait_0, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
### Which model is better#
x<-hold[1,]#
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/traits/nsp32-1-1.rdata', verbose=T)
out.hold<-lapply(nsp32_lambda1_lambdatrait_1, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
### Which model is better#
x<-hold[1,]#
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)
hold
length(which(hold[,2]>0.5))/100
length(which(hold[,2]>0.6667))/100
length(which(hold[,2]>0.745))/100
length(which(hold[,2]>0.95))/100
length(which(hold[,2]>0.90))/100
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
### Which model is better#
x<-hold[1,]#
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)
hold
apply(hold, 1, mean)
apply(hold, 2, mean)
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/traits/nsp16.rdata', verbose=T)
out.hold<-lapply(nsp16_lambda0_lambdatrait_0, extract.summary)
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)
apply(hold, 2, mean)
bci.inf<-hold[,1]/hold[,2]
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
bci.inf<-hold[,1]/hold[,2]
mean(bci.inf)
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)
hold<-data.frame(hold);names(hold)<-c("NOM","POM")
apply(hold, 2, mean)
hold[,1]
hold[,2]
hold[,1]/hold[,2]
bci.inf<-hold[,1]/hold[,2]
mean(bci.inf)
length(which(hold[,2]>0.95))/100
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)
length(which(hold[,2]>0.95))/100
out.hold<-lapply(nsp16_lambda0_lambdatrait_1, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
apply(hold, 2, mean)#
#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
length(which(hold[,2]>0.95))/100
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)
length(which(hold[,2]>0.95))/100
out.hold<-lapply(nsp16_lambda1_lambdatrait_0, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
apply(hold, 2, mean)#
#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
### Quick assay of type I error rate. What model weight cut off is right???#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)#
length(which(hold[,2]>0.95))/100
out.hold<-lapply(nsp16_lambda1_lambdatrait_1, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
apply(hold, 2, mean)#
#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)
length(which(hold[,2]>0.95))/100
length(which(hold[,2]>0.75))/100
out.hold<-lapply(nsp16_lambda1_lambdatrait_0, extract.summary)
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)#
length(which(hold[,2]>0.95))/100#
length(which(hold[,2]>0.75))/100
out.hold<-lapply(nsp16_lambda0_lambdatrait_1, extract.summary)
### Quick assay of type I error rate. What model weight cut off is right???#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)#
length(which(hold[,2]>0.95))/100#
length(which(hold[,2]>0.75))/100
out.hold<-lapply(nsp16_lambda0_lambdatrait_0, extract.summary)
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)#
length(which(hold[,2]>0.95))/100#
length(which(hold[,2]>0.75))/100
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/traits/nsp32-1-1.rdata', verbose=T)#
out.hold<-lapply(nsp32_lambda1_lambdatrait_1, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
apply(hold, 2, mean)#
#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)#
#
### Wh
## Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)#
#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)
length(which(hold[,2]>0.95))/100
length(which(hold[,2]>0.75))/100
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/traits/nsp32-1-0.rdata', verbose=T)
out.hold<-lapply(nsp32_lambda1_lambdatrait_0, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
apply(hold, 2, mean)#
#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)
length(which(hold[,2]>0.95))/100
length(which(hold[,2]>0.75))/100
0.75^5
0.8^5
0.9^5
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/traits/nsp16.rdata', verbose=T)
out.hold<-lapply(nsp16_lambda0_lambdatrait_0, extract.summary)
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)
length(which(hold[,2]>0.95))/100
length(which(hold[,2]>0.75))/100
length(which(hold[,2]>0.6667))/100
setwd('~/Dropbox/ccb_banding')
source('analyses/multi-species-phylo/src/initialize.R')
source('analyses/occupancy-phylo/src/initialize.R')
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/RJMCMC/Chase/POM_mods_ChaseData_nsp_123.rdata', verbose=T)
res.psi.betas
res.psi.betas$bugs
res.psi.betas$BUGSoutput$summary
sumz<-res.psi.betas$BUGSoutput$summary
show<-c('mean', '2.5%', '97.5%')
sumz[,show]
round(sumz[,show], 3)
round(sumz[,show], 2)
write.csv(round(sumz[,show], 2), file='~/Desktop/ChaseParamEst.csv')
sumz2<-round(sumz[,show], 2)
paste(sumz2[,2], sumz2[,3])
paste(sumz2[,2], sumz2[,3], sep=", ")
paste("(", sumz2[,2], " ,",sumz2[,3], ")", sep="")
paste("(", sumz2[,2], ", ",sumz2[,3], ")", sep="")
sumz2[,4]<-paste("(", sumz2[,2], ", ",sumz2[,3], ")", sep="")
sumz2$BCI<-paste("(", sumz2[,2], ", ",sumz2[,3], ")", sep="")
sumz<-res.psi.betas$BUGSoutput$summary#
show<-c('mean', '2.5%', '97.5%')#
sumz2<-round(sumz[,show], 2)
sumz2<-data.frame(sumz2)
sumz2$BCI<-paste("(", sumz2[,2], ", ",sumz2[,3], ")", sep="")
sumz3<-sumz2[,-c(2,3)]
sumz3
write.csv(sumz3, file='~/Desktop/ChaseParamEst.csv')
grep("psi.0.sp", row.names(sumz2))
sumz[grep("psi.0.sp", row.names(sumz)),]
expit(sumz[grep("psi.0.sp", row.names(sumz)),])
expit(sumz[grep("psi.0.sp", row.names(sumz)),])[,1]
mean(expit(sumz[grep("psi.0.sp", row.names(sumz)),])[,1])
sd(expit(sumz[grep("psi.0.sp", row.names(sumz)),])[,1])
expit(-0.75)
expit(-0.9)
expit(-0.6)
mean((sumz[grep("psi.0.sp", row.names(sumz)),])[,1])
sd((sumz[grep("psi.0.sp", row.names(sumz)),])[,1])
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/traits/nsp32-0-1.rdata', verbose=T)
out.hold<-lapply(nsp32_lambda0_lambdatrait_1, extract.summary)
### What's the breadth of the confidence intervals#
hold<-matrix(unlist(lapply(out.hold,function(x) {apply((x[,2:3]), 1, diff)})), ncol=2, byrow=T)#
apply(hold, 2, mean)#
#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Does the confidence interval contain the true value?#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,2] < 1 & x[,3] > 1})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
head(hold)#
apply(hold, 2, sum)
### Which estimate is closer to the true estimate?#
hold<-matrix(unlist(lapply(out.hold,function(x) {abs(x[,1]-1)})), ncol=2, byrow=T)#
hold<-data.frame(hold);names(hold)<-c("NOM","POM")#
apply(hold, 2, mean)#
#
bci.inf<-hold[,1]/hold[,2]#
mean(bci.inf)
### Which model is better#
apply(t(apply(hold, 1, function (x) {x==min(x)})), 2, sum)
### Quick assay of type I error rate. What model weight cut off is right???#
hold<-matrix(unlist(lapply(out.hold,function(x) {x[,6]})), ncol=2, byrow=T)#
length(which(hold[,2]>0.95))/100#
length(which(hold[,2]>0.75))/100
psi.vec<-c(0,0,1,0,1)
psi.vec
p.det<-0.25
X.vec<-c(0,0,1,0,1)
p.det<-0.25
psi<-0.6
X.vec
X.vec * p.det
(X.vec * p.det) + ((1- X.vec) * (1-p.det))
(X.vec * p.det) + ((1- X.vec) * (1-p.det)) * psi
prod( (X.vec * p.det) + ((1- X.vec) * (1-p.det)) )
prod( (X.vec * p.det) + ((1- X.vec) * (1-p.det)) ) * psi
(X.vec * p.det) + ((1- X.vec) * (1-p.det))
(X.vec * p.det) + ((1- X.vec) * (1-p.det)) * psi
dbinom(2, 5, 0.25)
(X.vec * p.det) + ((1- X.vec) * (1-p.det)) * psi
(X.vec * p.det) + ((1- X.vec) * (1-p.det))
(X.vec * p.det) + ((1- X.vec) * (1-p.det))  / 5
sum( (X.vec * p.det) + ((1- X.vec) * (1-p.det)) )  / 5
dbinom(2, 5, 0.25)
prod( (X.vec * p.det) + ((1- X.vec) * (1-p.det)) )
?dbinom
1 - (X.vec * p.det) + ((1- X.vec) * (1-p.det)
)
(X.vec * p.det) + ((1- X.vec) * (1-p.det))
dbinom(2, 5, 0.25)
dbinom(2, 5, 0.25) * psi
dbinom(2, 5, 0.25) * psi + (1-psi)*0
dbinom(0, 5, 0.25)
dbinom(0, 5, 0.25) * psi + (1-psi)*1
dbinom(0, 5, 0.25) * psi
(1-psi)*1
(X.vec * p.det) + ((1- X.vec) * (1-p.det))
prod((X.vec * p.det) + ((1- X.vec) * (1-p.det)))
##************************************************************************#
## Importance sampling code for Perry#
##************************************************************************#
rm(list=ls())#
setwd('~/Dropbox/ccb_banding/analyses/occupancy-phylo/for_perry')#
#
library(dclone)#
library(R2jags)#
library(scales)#
#
source('functionsFaster.R') ## These are the functions you sent to us,#
                            ## with a few modifications and additional#
                            ## functions.  Completely new, or updated#
                            ## functions begin on line 411
## compile C code and load resultant .so object#
fn.1 <- 'phyloOccLL.o'#
fn.2 <- 'phyloOccLL.so'#
fn.3 <- 'phyloOccLL.c'#
if(file.exists(fn.1)) file.remove(fn.1)#
if(file.exists(fn.2)) file.remove(fn.2)#
system(sprintf('R CMD SHLIB %s', fn.3))#
dyn.load(fn.2)#
#
## load the data which was simulated with lambda=0.5 and 32 species#
## (lambda=0.5 is important, because as will be shown later, the model#
## with lambda is the less likely model)#
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/dclone/POM_mods_lambda_0.5_nsp_32_V8.rdata',#
     verbose=TRUE)#
## load('POM_mods_lambda_0.5_nsp_32_V8.rdata', verbose=T)
set.seed(1)#
n.batch <- 1#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=4)
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=4)
length(attr(mod.lam,  'lik.vals'))
length(attr(mod.null, 'lik.vals'))
round(attr(mod.lam,  'stat.sum'), 4)
round(attr(mod.null, 'stat.sum'), 4)
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')
anova.pom(mod.lam, mod.null)
set.seed(1)#
n.batch <- 10#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=4)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=4)#
#
## Total number of draws#
length(attr(mod.lam,  'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam,  'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 473 in functionsFaster.R.  Blue#
## (respectively, red) corresponds to draws from models with#
## (respectively without) lambda.#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
##************************************************************************#
## Importance sampling code for Perry#
##************************************************************************#
rm(list=ls())#
setwd('~/Dropbox/ccb_banding/analyses/occupancy-phylo/for_perry')#
#
library(dclone)#
library(R2jags)#
library(scales)#
#
source('functionsFaster.R') ## These are the functions you sent to us,#
                            ## with a few modifications and additional#
                            ## functions.  Completely new, or updated#
                            ## functions begin on line 411#
#
## compile C code and load resultant .so object#
fn.1 <- 'phyloOccLL.o'#
fn.2 <- 'phyloOccLL.so'#
fn.3 <- 'phyloOccLL.c'#
if(file.exists(fn.1)) file.remove(fn.1)#
if(file.exists(fn.2)) file.remove(fn.2)#
system(sprintf('R CMD SHLIB %s', fn.3))#
dyn.load(fn.2)#
#
## load the data which was simulated with lambda=0.5 and 32 species#
## (lambda=0.5 is important, because as will be shown later, the model#
## with lambda is the less likely model)#
load('~/Dropbox/ccb_banding/analyses/occupancy-phylo/saved/dclone/POM_mods_lambda_0.5_nsp_32_V8.rdata',#
     verbose=TRUE)#
## load('POM_mods_lambda_0.5_nsp_32_V8.rdata', verbose=T)#
#
#####################################################################
## Calculate LL with small number of draws#
#####################################################################
#
## If this is repeated a few times the resulting p-values vary quite #
## a bit#
#
set.seed(1)#
n.batch <- 1#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T)#
#
## Total number of draws#
length(attr(mod.lam,  'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam,  'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 473 in functionsFaster.R.  Blue#
## (respectively, red) corresponds to draws from models with#
## (respectively without) lambda.#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
n.batch <- 10#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=5)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=5)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
n.batch <- 10#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=5)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=5)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
n.batch <- 10#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=5)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=5)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
n.batch <- 10#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=5)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=5)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
## Same behavior even with more draws#
#
n.batch <- 20#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=7)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=7)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
## Same behavior even with more draws#
#
n.batch <- 20#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=7)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=7)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
## Same behavior even with more draws#
#
n.batch <- 20#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=7)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=7)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
40*8*10000
50*8*10000
60*8*10000
100*8*10000
120*8*10000
122*8*10000
125*8*10000
n.batch <- 5#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=T,#
                  n.cores=8)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=T,#
                   n.cores=8)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5))#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5))#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=10)
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=100)
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5), breaks=100)
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=100)#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5), breaks=100)#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=100)#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5), breaks=50)#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')
n.batch <- 5#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=F,#
                  n.cores=8)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=F,#
                   n.cores=8)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=100)#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5), breaks=50)#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
n.batch <- 5#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=F,#
                  n.cores=8)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=F,#
                   n.cores=8)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=100)#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5), breaks=50)#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
n.batch <- 100#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=F,#
                  n.cores=8)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=F,#
                   n.cores=8)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=100)#
abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5), breaks=50)#
abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
## Same behavior even with more draws#
#
n.batch <- 100#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=F,#
                  n.cores=8)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=F,#
                   n.cores=8)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
# hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=100)#
# abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
# hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5), breaks=50)#
# abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
n.batch <- 200#
#
#set.seed(1)#
#
mod.lam <- pom.LL(mod.lam,#
                  n.batches=n.batch,#
                  batch.size=10000,#
                  save.all.LLs=F,#
                  n.cores=4)#
#
mod.null <- pom.LL(mod.null,#
                   n.batches=n.batch,#
                   batch.size=10000,#
                   save.all.LLs=F,#
                   n.cores=4)#
#
## Total number of draws#
length(attr(mod.lam, 'lik.vals'))#
length(attr(mod.null, 'lik.vals'))#
#
## SE.LL reports the standard error, calculated in line 480 in#
## functionsFaster.R#
round(attr(mod.lam, 'stat.sum'), 4)#
round(attr(mod.null, 'stat.sum'), 4)#
#
## Histograms of LLs for both models. Vertical line represents mean,#
## as calculated on line 478 in functionsFaster.R#
# hist(attr(mod.lam, 'lik.vals'), col=alpha('blue', 0.5), breaks=100)#
# abline(v=attr(mod.lam, 'stat.sum')['LL'], col='blue')#
# hist(attr(mod.null, 'lik.vals'), add=T, col=alpha('red', 0.5), breaks=50)#
# abline(v=attr(mod.null, 'stat.sum')['LL'], col='red')#
#
anova.pom(mod.lam, mod.null)
